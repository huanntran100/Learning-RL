{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search and Hill Climbing on CartPole-v0\n",
    "Based on: http://kvfrans.com/simple-algoritms-for-solving-cartpole/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "timeSteps = 200 # Time steps per episode\n",
    "randomTimeSteps = 10000 # Time steps for multiepisodic training\n",
    "observationSpace = 4 # Size of CartPole-v0 observation vector\n",
    "actionSpace = 2 # Size of CartPole-v0 action vector\n",
    "noise = 0.001 # Noise scaling for hill climbing\n",
    "noiseStep = 0.001 # Noise increase for hill climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole-v0  \n",
    "I run a random simulation of the environement to get an idea of how the observations and actions look, and what balancing the pole without an optimal policy looks like. For the following experiments, a terminal state is defined as 1) when pole fails to be balanced or 2) when t = 200 timesteps. Solving is defined here https://gym.openai.com/envs/CartPole-v0/ as achieving an average cumulative reward of 195.0+ over 100 consecutive trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-12-15 21:51:01,855] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done on timestep: 31\n",
      "Example of action: 0\n",
      "Example of observation: [-0.10130247 -0.83506247  0.21682023  1.65809761]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    if done == True:\n",
    "        print('Done on timestep:', _)\n",
    "        print('Example of action:', action)\n",
    "        print('Example of observation:', observation)\n",
    "        break \n",
    "env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run_episode(env, parameters)** takes weights and environment as input and returns total reward for linear approximation.  \n",
    "**run_10_trials(env, parameters)** takes weights and environment as input and prints the results of running the environment 100 times for a 10 trials with the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, parameters):\n",
    "    observation = env.reset()\n",
    "    totalReward = 0\n",
    "    for i in range(timeSteps):\n",
    "        # Choose action based on linear approximation\n",
    "        if np.matmul(observation, parameters) < 0: \n",
    "            action = 0\n",
    "        else: \n",
    "            action = 1\n",
    "        # Take a step in the environment\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        # Append non-discounted cumulative reward \n",
    "        totalReward += reward \n",
    "        # If done, end the episode \n",
    "        if done:\n",
    "            break \n",
    "    return totalReward \n",
    "\n",
    "def run_10_trials(env, parameters):\n",
    "    print('Using the following best parameters: ', parameters)\n",
    "    for i in range(10):\n",
    "        overallReward = []\n",
    "        for j in range(100):\n",
    "            episodeReward = run_episode(env, parameters)\n",
    "            overallReward.append(episodeReward)\n",
    "        print('Trial', i, ': The average reward over 100 consecutive trials is:', np.mean(overallReward), 'and the max reward is:', np.max(overallReward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search Algorithm\n",
    "Generate 10,000 random configurations of parameters and find the set of weights that returns the greatest cumulative reward per episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 , Best Params: [ 0.15168838  0.86322282 -0.47353671  0.5841737 ] , Episode Reward: 9.0\n",
      "Episode: 3 , Best Params: [ 0.55149192  0.43250818  0.29038242  0.58593235] , Episode Reward: 10.0\n",
      "Episode: 6 , Best Params: [ 0.55149192  0.43250818  0.29038242  0.58593235] , Episode Reward: 37.0\n",
      "Episode: 9 , Best Params: [ 0.55149192  0.43250818  0.29038242  0.58593235] , Episode Reward: 9.0\n",
      "Episode: 12 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 119.0\n",
      "Episode: 15 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 10.0\n",
      "Episode: 18 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 141.0\n",
      "Episode: 1000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 158.0\n",
      "Episode: 2000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 103.0\n",
      "Episode: 3000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 9.0\n",
      "Episode: 4000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 9.0\n",
      "Episode: 5000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 31.0\n",
      "Episode: 6000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 8.0\n",
      "Episode: 7000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 10.0\n",
      "Episode: 8000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 50.0\n",
      "Episode: 9000 , Best Params: [-0.32372492  0.15901937  0.96234089  0.91835329] , Episode Reward: 79.0\n",
      "Total random search training time: 4.570363521575928 seconds\n",
      "Average episodes to reach 200 timesteps: 13.6546\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d70a9534a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "bestParameters = None \n",
    "bestTotalReward = 0 \n",
    "\n",
    "episodeBeforeSolve = []\n",
    "startEpisode = 0\n",
    "endEpisode = 0\n",
    "\n",
    "for _ in range(randomTimeSteps):\n",
    "    env.reset()\n",
    "    endEpisode = _ \n",
    "    \n",
    "    # Make random parameters \n",
    "    episodeParameters = np.random.uniform(-1, 1, size = observationSpace)\n",
    "    \n",
    "    # Run episode with random parameters\n",
    "    episodeReward = run_episode(env, episodeParameters)\n",
    "    if episodeReward > bestTotalReward: \n",
    "        bestTotalReward = episodeReward \n",
    "        bestParameters = episodeParameters \n",
    "    else: \n",
    "        bestTotalReward = bestTotalReward\n",
    "        bestParameters = bestParameters  \n",
    "    \n",
    "    # Get time steps until solve\n",
    "    episodeBeforeSolve.append(endEpisode - startEpisode)\n",
    "    if episodeReward == timeSteps:\n",
    "        startEpisode = endEpisode\n",
    "        \n",
    "    # Training log \n",
    "    if _ < 20:\n",
    "        if _ % 3 == 0: \n",
    "            print('Episode:', _, ', Best Params:', bestParameters, ', Episode Reward:', episodeReward)\n",
    "    else:\n",
    "        if _ % 1000 == 0:\n",
    "            print('Episode:', _, ', Best Params:', bestParameters, ', Episode Reward:', episodeReward)\n",
    "            \n",
    "\n",
    "end_time = time.time()\n",
    "print('Total random search training time:', end_time - start_time, 'seconds')\n",
    "\n",
    "# Plot weight distribution\n",
    "n = plt.hist(episodeBeforeSolve, bins = range(200))\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('# Episodes Before Solve')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "average = sum(episodeBeforeSolve)/len(episodeBeforeSolve)\n",
    "print('Average episodes to reach 200 timesteps:', average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then take the best policy weights and determine if the environment is solved by running 100 consecutive trials and finding the average cumulative reward. Clearly, the random search algorithm performs well by getting average scores of over 195.0+ for 3 experimental trials, demonstrating the reproducibility of the policy. The drawback to this method is that it does not scale well into continuous state/action spaces. Since we only have two actions in this environment, randomly searching will do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following best parameters:  [ 10120.41473844 -21620.65029317  41313.47961883  30968.88313772]\n",
      "Trial 0 : The average reward over 100 consecutive trials is: 167.69 and the max reward is: 200.0\n",
      "Trial 1 : The average reward over 100 consecutive trials is: 171.56 and the max reward is: 200.0\n",
      "Trial 2 : The average reward over 100 consecutive trials is: 161.64 and the max reward is: 200.0\n",
      "Trial 3 : The average reward over 100 consecutive trials is: 164.77 and the max reward is: 200.0\n",
      "Trial 4 : The average reward over 100 consecutive trials is: 148.57 and the max reward is: 200.0\n",
      "Trial 5 : The average reward over 100 consecutive trials is: 159.53 and the max reward is: 200.0\n",
      "Trial 6 : The average reward over 100 consecutive trials is: 159.43 and the max reward is: 200.0\n",
      "Trial 7 : The average reward over 100 consecutive trials is: 159.57 and the max reward is: 200.0\n",
      "Trial 8 : The average reward over 100 consecutive trials is: 159.59 and the max reward is: 200.0\n",
      "Trial 9 : The average reward over 100 consecutive trials is: 160.22 and the max reward is: 200.0\n"
     ]
    }
   ],
   "source": [
    "run_10_trials(env, bestParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hill Climbing\n",
    "Initialize random weight and gradually increase in with noise until we find the best set of weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1000 , Best Params: [ 1856.37680183 -7200.69253775  7461.0862475   5586.57162402] , Episode Reward: 200.0\n",
      "Episode: 2000 , Best Params: [   714.03005594   -903.64822383  15101.5121453   11551.5119267 ] , Episode Reward: 200.0\n",
      "Episode: 3000 , Best Params: [  3550.7745103    5221.56297251  23889.40939149  15833.51515279] , Episode Reward: 200.0\n",
      "Episode: 4000 , Best Params: [  3033.67445373    621.30953936  36021.51791537  28448.73836001] , Episode Reward: 200.0\n",
      "Episode: 5000 , Best Params: [  3699.21701003  -3418.23991344  31836.51344487  28305.27313991] , Episode Reward: 200.0\n",
      "Episode: 6000 , Best Params: [ 10321.14900777  -4731.40019022  28501.4097637   30331.95221915] , Episode Reward: 181.0\n",
      "Episode: 7000 , Best Params: [ 18702.08758104 -14284.492356    29425.26308084  25601.33172679] , Episode Reward: 111.0\n",
      "Episode: 8000 , Best Params: [ 16660.79596472 -15549.73703127  29025.38846285  26715.08091774] , Episode Reward: 89.0\n",
      "Episode: 9000 , Best Params: [ 20267.05302122 -23995.26908718  33765.92383694  28492.64128518] , Episode Reward: 185.0\n",
      "Total hill climb training time: 14.54141116142273 seconds\n",
      "Average episodes to reach 200 timesteps: 4.5812\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d70f762ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "bestParameters = None \n",
    "bestTotalReward = 0 \n",
    "episodeParameters = np.random.uniform(-1, 1, size = observationSpace)\n",
    "\n",
    "episodeBeforeSolve = []\n",
    "startEpisode = 0\n",
    "endEpisode = 0\n",
    "\n",
    "for _ in range(randomTimeSteps):\n",
    "    env.reset()\n",
    "    endEpisode = _ \n",
    "    \n",
    "    # Random hill climbing \n",
    "    episodeNoise = np.random.uniform(-1, 1, size = observationSpace) * noise \n",
    "    episodeParameters += episodeNoise\n",
    "     \n",
    "    # Run episode with random parameters\n",
    "    episodeReward = run_episode(env, episodeParameters)\n",
    "    if episodeReward > bestTotalReward: \n",
    "        bestTotalReward = episodeReward \n",
    "        bestParameters = episodeParameters \n",
    "    else:\n",
    "        noise += noiseStep\n",
    "        bestTotalReward = bestTotalReward\n",
    "        bestParameters = bestParameters  \n",
    "    \n",
    "    # Get time steps until solve\n",
    "    episodeBeforeSolve.append(endEpisode - startEpisode)\n",
    "    if episodeReward == timeSteps:\n",
    "        startEpisode = endEpisode\n",
    "\n",
    "    # Training log \n",
    "    if _ % 1000 == 0 and _ != 0:\n",
    "        print('Episode:', _, ', Best Params:', bestParameters, ', Episode Reward:', episodeReward)\n",
    "\n",
    "end_time = time.time()\n",
    "print('Total hill climb training time:', end_time - start_time, 'seconds')\n",
    "\n",
    "# Plot weight distribution \n",
    "n = plt.hist(episodeBeforeSolve, bins = range(200))\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Episodes Needed to Solve')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "average = sum(episodeBeforeSolve)/len(episodeBeforeSolve)\n",
    "print('Average episodes to reach 200 timesteps:', average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again take the best parameters and perform 3 trials of 100 episodes each. Hill Climbing does not reliably produce a set of good weights that achieve the \"solving\" goal if we initialize with a bad set of weights. Therefore, we have to repeat running the algorithm to output a good policy that holds the pole up most of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following best parameters:  [ 10120.41473844 -21620.65029317  41313.47961883  30968.88313772]\n",
      "Trial 0 : The average reward over 100 consecutive trials is: 161.38 and the max reward is: 200.0\n",
      "Trial 1 : The average reward over 100 consecutive trials is: 165.78 and the max reward is: 200.0\n",
      "Trial 2 : The average reward over 100 consecutive trials is: 161.7 and the max reward is: 200.0\n",
      "Trial 3 : The average reward over 100 consecutive trials is: 152.47 and the max reward is: 200.0\n",
      "Trial 4 : The average reward over 100 consecutive trials is: 171.18 and the max reward is: 200.0\n",
      "Trial 5 : The average reward over 100 consecutive trials is: 154.9 and the max reward is: 200.0\n",
      "Trial 6 : The average reward over 100 consecutive trials is: 155.76 and the max reward is: 200.0\n",
      "Trial 7 : The average reward over 100 consecutive trials is: 151.6 and the max reward is: 200.0\n",
      "Trial 8 : The average reward over 100 consecutive trials is: 156.4 and the max reward is: 200.0\n",
      "Trial 9 : The average reward over 100 consecutive trials is: 159.91 and the max reward is: 200.0\n"
     ]
    }
   ],
   "source": [
    "run_10_trials(env, bestParameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
